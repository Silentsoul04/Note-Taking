爬虫的设计思路：
1. 确定需要爬取的URL
2. 获取对应的HTML页面
3. 提取HTML页面数据
   * 如果是目标数据，就储存
   * 如果是页面里包含其他URL，则重复2、3步骤

***

## URL

HTTP请求的处理库：urllib、urllib2、requests

## 解析 HTML 页面

使用re、xpath、BeautifulSoup4（bs4）、jsonpath、pyquery等库来进行服务器响应的处理。

具体的处理就是使用某种描述性语言来给我们需要提取的数据定义一个匹配规则，符合这个规则的数据就会被匹配。

## 爬虫 - 反爬虫 - 反反爬虫

通用的反爬虫技术：User-Agent、代理、验证码、动态数据加载、加密数据。

采集动态HTML以及验证码的处理

通用的动态页面采集：Selenium + PhantomJS(无界面)：模拟真实浏览器加载js、ajax等非静态页面数据
对于验证码的处理可以使用 Tesseract库，这是一个Google的机器学习库，基于机器图像识别系统，可以处理简单的验证码。但是复杂的验证码可以通过手动输入或者找专门的打码平台来处理。

